\section{Chapter Summary}
Formal verification of different fairness metrics of machine learning for different datasets is an important question. Existing fairness verifiers, however, are not scalable, accurate, and extendable to non-Boolean sensitive features. We propose a stochastic SAT-based approach, {\justicia}, that formally verifies multiple group and causal fairness metrics for different classifiers and distributions for compound sensitive groups.
Experimental evaluations demonstrate that {\justicia} achieves \textit{higher accuracy} and \textit{scalability} in comparison to the state-of-the-art verifiers, FairSquare and VeriFair, while yielding \textit{higher robustness} than the sample-based tools, such as AIF360.

Our work opens up several new directions of research. One direction is to develop SSAT models and verifiers for popular classifiers like deep networks and SVMs. Other direction is to develop SSAT solvers that can accommodate continuous variables and conditional probabilities by design.
%Of particular interest is the highlighted need for design of efficient SSAT solvers given that SSAT can be viewed as a natural target problem in the context of development of formal verification techniques for fairness.

%In this paper, we focus on formal verification of whether a given model satisfies a given fairness criterion. To this end, we proposed a stochastic SAT-based approach, {\justicia}, that formally verifies independence and separation metrics of fairness for different classifiers and distributions. We demonstrates that {\justicia} achieves higher accuracy and scalability in comparison to the prior state of the art approaches while achieving higher robustness in comparison to purely dataset based approaches such as AIF360. Our work opens up several directions of new research. Of particular interest is the highlighted need for design of efficient SSAT solvers given that SSAT can be viewed as a natural target problem in the context of development of formal verification techniques for fairness. 