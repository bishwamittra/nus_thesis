\section{Background: Fairness and SSAT}
\label{fairness_justicia_sec:preliminaries}
In this section, we define different fairness metrics for a supervised learning problem. Following that, we discuss Stochastic Boolean Satisfiability (SSAT) problem.

\subsection{Fairness Metrics for Machine Learning}\label{fairness_justicia_sec:fairness}
Let us represent a dataset $D$ as a collection of triples $(X, A, Y)$ sampled from an underlying data generating distribution $\mathcal{D} $.
$X \triangleq \lbrace \nonsensitive_1, \ldots, \nonsensitive_m\rbrace \in \mathbb{R}^m $ is the set of non-protected (or non-sensitive) attributes.
$A \triangleq \lbrace A_1, \ldots, A_n\rbrace$ is the set of categorical protected attributes.
$Y$ is the binary label (or class) of $(X, A)$. 
A compound protected attribute $\mathbf{a} = \{a_1, \ldots, a_n\}$ is a valuation to all $A_i$'s and represents a \textit{compound protected} group. For example, $A = \{\textrm{race}, \textrm{sex}\}$, where $\textrm{race} \in \{\textrm{Asian}, \textrm{Colour}, \textrm{White}\}$ and  $\textrm{sex} \in \{\textrm{female},  \textrm{male}\}$. 
Thus, $\mathbf{a} =  \{\textrm{Colour}, \textrm{female}\}$ is a compound protected group. 
We define $\alg \triangleq \Pr(\hat{Y}|X, A)$ to be a binary classifier trained from samples in the distribution $\mathcal{D} $. 
Here, $\hat{Y}$ is the predicted label (or class) of the corresponding data.

As we illustrated in Example~\ref{fairness_justicia_example:intro}, a classifier $\alg$ that solely optimizes accuracy, i.e., the average number of times $\hat{Y} = Y$, may discriminate certain compound protected groups over others~\cite{chouldechova2020snapshot}.
Now, we describe two family of fairness metrics that compute bias induced by a classifier and are later verified by {\justicia}.

\begin{comment}
$ X $ is the set of non-protected attributes. Each non-protected attribute $ x_i \in X $ takes the valuation as real numbers or categories. 
We consider a multi-protected attributes setting where $ A $ is the set of protected (or sensitive) attributes. Each protected attribute $ a_i \in A $ is a categorical attribute with at least two categories.  
$ y $ is the binary class label of the data sample. 

Based on the valuation of the protected attributes, the samples are  tagged as being in different protected groups, i.e., 
the privileged group(s)  and the unprivileged group(s). For instance, let the dataset contain two protected attributes:  race and gender. The attribute race can be white, black or Asian and the attribute gender can be male or female. For simplicity, we assume that the protected group white-male is the most privileged group and all other protected groups (attribute combinations) refer to unprivileged groups with black-female being the most unprivileged group. Generally the dataset contains bias that results in the discrimination between the privileged and unprivileged groups. In this paper, we do not require the knowledge of privileged and unprivileged groups beforehand. We instead ask for the set $ A $ of protected attributes from which we derive privileged and unprivileged groups. 
\end{comment}



\begin{comment}
We now consider a more specific setting where the samples are divided into privileged and unprivileged groups based on the valuation of $ a $, i.e, when $ a=1 $, the sample is included into a privileged group and vice versa. 
\end{comment}


\subsubsection{Independence Metrics of Fairness.} 
The \textit{independence (or calibration) metrics} of fairness state that the output of the classifier should be independent of the compound protected group.
A notion of independence is referred to \textit{group fairness} that specifies an \textit{equal positive predictive value (PPV) across all compound protected groups} for an algorithm $\alg$, i.e., $\Pr[\hat{Y} = 1 | A = \mathbf{a}, \alg] = \Pr [\hat{Y} =1 | A = \mathbf{b}, \alg], \forall \mathbf{a}, \mathbf{b} \in A$.
Since satisfying group fairness exactly is hard, relaxations of group fairness, such as \textit{disparate impact} and \textit{statistical parity}~\cite{dwork2012fairness,feldman2015certifying}, are proposed. 

\textit{Disparate impact} (DI)~\cite{feldman2015certifying} measures the ratio of PPVs between the most favored group and least favored group, and prescribe it to be close to $1$. Formally, a classifier satisfies $(1 - \epsilon)$-disparate impact if, for $\epsilon \in [0,1] $,
\[
	\min_{\mathbf{a} \in A} \Pr[\hat{Y} =1 | \mathbf{a}, \alg]  \ge (1 - \epsilon) \max_{\mathbf{b} \in A} \Pr[\hat{Y} =1 | \mathbf{b}, \alg].
\]
Another popular relaxation of group fairness, \textit{statistical parity} (SP) measures the difference of PPV among the compound groups, and prescribe this to be near zero. Formally, an algorithm satisfies $\epsilon$-statistical parity if, for $\epsilon \in [0,1] $, 
\[
\max_{\mathbf{a}, \mathbf{b} \in A}|\Pr[\hat{Y} =1 | \mathbf{a}, \alg] - \Pr [\hat{Y} = 1| \mathbf{b}, \alg]| \le \epsilon.
\]
For both disparate impact and statistical parity, lower value of $\epsilon$ indicates higher group fairness of the classifier $\alg$. 


\begin{comment}These two metrics of fairness has a disadvantage that a fully accurate classifier with different base rates (i.e., the proportion of actual positive prediction) in different protected groups may be considered unfair. As a result, similar individuals from different protected groups may be treated differently in order to achieve group fairness{\textemdash} such treatment is prohibited by law in some cases. 
\end{comment}

\subsubsection{Separation Metrics of Fairness.}
In the \textit{separation (or classification parity)} notion of fairness, the predicted label $\hat{Y}$ of a classifier $\alg$ is independent of the sensitive attributes $A$ given the actual class labels $Y$. In case of binary classifiers, a popular separation metric is \textit{equalized odds} (EO)~\cite{hardt2016equality} that computes the difference of false positive rates (FPR) and the difference of true positive rates (TPR) among all compound protected groups. 
Lower value of equalized odds indicates better fairness.
A classifier $\alg$ satisfies $\epsilon$-equalized odds if, for all compound protected groups $\mathbf{a}, \mathbf{b} \in A$,
\begin{equation}
\begin{split}
|\Pr[\hat{Y} =1 | A = \mathbf{a}, Y= 0  ] - \Pr [\hat{Y} = 1| A = \mathbf{b}, Y = 0]| &\le \epsilon, \\ 
|\Pr[\hat{Y} =1 | A = \mathbf{a}, Y= 1  ] - \Pr [\hat{Y} = 1| A = \mathbf{b}, Y = 1]| &\le \epsilon.\notag
\end{split}
\end{equation}



%\begin{comment}
%In contrast to disparate impact and statistical parity difference metrics, a fully accurate classifier will necessarily satisfy the two constraints in equalized odds measure. 

%\textbf{Group fairness.}  Group fairness requires the probability for an individual to be assigned the favorable outcome to be equal across the privileged  and unprivileged groups. Throughout the manuscript, by favorable outcome we refer to the predictor $ \hat{y} = 1 $ in  the standard binary classification setting. Now group fairness is formally defined in the following. 
%
%\[
%\Pr(\hat{y} =1 | a =1  ) = \Pr (\hat{y} = 1| a = 0)
%\]
%
%By abusing notations, we use the following shorthand. 
%
%\[
%\Pr_1(\hat{y} =1) = \Pr_0(\hat{y} = 1)
%\]
%
%
%
%
%In practice, the above definition can be relaxed. Thus we define the notion of $ \epsilon $-\textit{group fairness} in the following. 
%\[
% |\Pr_1(\hat{y} =1) - \Pr_0(\hat{y} = 1) |< \epsilon
%\]
%
%\end{comment}

In this paper, we formulate verifying the aforementioned independence and separation metrics of fairness as stochastic Boolean satisfiability (SSAT) problem, which we define next. 

\subsection{Stochastic Boolean Satisfiability (SSAT)}\label{fairness_justicia_sec:ssat}
Let $\mathbf{B}  = \{\bool_1, \dots, \bool_m\}  $ be a set of Boolean variables. A \textit{literal} is a variable $ \bool_i $ or its complement $ \neg \bool_i $. 
A propositional formula $\phi$ defined over $\mathbf{B}$ is in \textit{Conjunctive Normal Form (CNF)} if $\phi$   is  a conjunction of clauses and each clause is a disjunction of literals. 
%\red{DNF (disjunctive normal form) is the  complement of CNF where  the formula is a disjunction of clauses and each clause is  a conjunction of literals.} 
Let $ \sigma $ be an assignment to the  variables $ \bool_i \in \mathbf{B} $  such that $ \sigma(\bool_i) \in \{1, 0\} $ where $ 1 $ is logical TRUE and $ 0 $ is logical FALSE. The propositional  \textit{satisfiability} problem (SAT)~\cite{biere2009handbook} finds an assignment $ \sigma $ to all $ \bool_i \in  \mathbf{B} $ such that the formula $ \phi $ is evaluated to be $1$. 
In contrast to the SAT problem, the \textit{Stochastic Boolean Satisfiability} (SSAT) problem~\cite{littman2001stochastic} is concerned with the  probability of the satisfaction of the formula $\phi$. 
An SSAT formula is of the form
\begin{equation}\label{fairness_justicia_eq:ssat}
\Phi = Q_1\bool_1, \dots, Q_m \bool_m,\; \phi, 
\end{equation}
where $ Q_i \in \{\exists, \forall, \R^{p_i}\} $ is either of the existential ($\exists$), universal ($\forall$), or randomized ($\R^{p_i}$) quantifiers over the Boolean variable $\bool_i$ and $\phi$ is a quantifier-free CNF formula. In the SSAT formula $ \Phi $, the quantifier part $ Q_1\bool_1, \dots, Q_m \bool_m $ is known as the \textit{prefix} of the formula $ \phi $. In case of randomized quantification $ \R^{p_i} $, $ p_i \in [0,1] $ is the probability of $ \bool_i $ being assigned to $ 1 $. Given an SSAT formula $ \Phi $, let $ \bool $ be the outermost variable in the prefix. The satisfying probability of $ \Phi $ can be computed by the following \textit{rules}:
\begin{enumerate}
	\item $ \Pr[\text{TRUE}] = 1 $,  $ \Pr[\text{FALSE}] = 0 $, 
	\item $ \Pr [\Phi] = \max_{\bool} \{\Pr[\Phi|_{\bool}], \Pr[\Phi|_{\neg \bool}]\}$ if $ \bool $ is existentially quantified ($ \exists $), 
	\item $ \Pr [\Phi] = \min_{\bool} \{\Pr[\Phi|_{\bool}], \Pr[\Phi|_{\neg \bool}]\} $ if $ \bool $ is universally quantified ($ \forall $), 
	\item $ \Pr [\Phi] = p\Pr[\Phi|_{\bool}] + (1-p) \Pr[\Phi|_{\neg \bool}] $ if $ \bool $ is randomized quantified ($\R^{p}$) with probability $p$ of being $\text{TRUE}$,
\end{enumerate}
where $ \Phi|_{\bool} $ and $ \Phi|_{\neg \bool} $ denote the SSAT formulas derived by eliminating the outermost quantifier of $ \bool $  by substituting the value of $ \bool $ in the formula $ \phi $ with $ 1 $ and $ 0 $ respectively. In this paper, we focus on two specific types of SSAT formulas:  \textit{random-exist} (RE) SSAT and \textit{exist-random} (ER) SSAT. In the ER-SSAT (resp.\ RE-SSAT) formula, all existentially (resp.\ randomized) quantified variables are followed by randomized (resp.\ existentially) quantified variables in the prefix.
\begin{lemma}{~\cite{littman2001stochastic}}
	\label{fairness_justicia_thm:complexity}
	Solving the ER-SSAT and RE-SSAT problems are $\mathrm{NP}^{\mathrm{PP}}$ hard.
\end{lemma}

The problem of SSAT and its variants have been pursued by theoreticians and practitioners alike for over three decades~\cite{majercik2005dc,fremont2017maximum,huang2006combining}. We refer the reader to~\cite{lee2017solving,lee2018solving} for detailed survey. It is worth remarking that the past decade has witnessed a significant performance improvements thanks to close integration of techniques from SAT solving with advances in weighted model counting~\cite{sang2004combining,chakraborty2013scalable,chakraborty2014distribution}. 






%In these extreme situations, the reduced problem is NP-hard and PP-hard respectively.
%We can show solving ER- and RE-SSAT are equivalent to solving an E-MAJSAT/e-threshold SAT problem. Thus it is $NP^{PP}$ hard. 
%Equivalent formulation of this is computing MAP in a belief network.


\begin{comment}
	The Stochastic Boolean Satisfiability problem (SSAT) allows existential ($ \exists $) and randomized ($ \R $) quantifiers over the Boolean variables and evaluates the probability of satisfaction of the CNF formula.  Based on the order of quantified variables, an SSAT instance can be either a random-exists (\textbf{RE}) SSAT  formula or an exist-random (\textbf{ER}) SSAT formula.  
	
	Let $ \phi(E,R) $ be a CNF formula over Boolean variables $ E \cup R $ where each $ e_i \in E $ is an exist quantified variable and each $ r_j \in R $ is a randomized quantified variable.  For each $ r_j $, $ p_j = \Pr(\sigma(r_j) = 1) $ denotes the probability of $ r_j $ assigning to TRUE. Now an \textbf{RE}-SSAT formula is defined as 
	
	\[
	\R^{p_1} r_1, \dots, \R^{p_m} r_m, \exists e_1, \dots, \exists e_n \; \phi (E,R)
	\]
	
	where $ |R| = m,  |E| = n  $. Intuitively,  for the random assignment of $ r_1, \dots, r_m $ there exists assignments of $ e_1, \dots, e_n $, for which, we ask the \red{maximum}  probability of satisfaction of $ \phi $. Similarly, an \textbf{ER}-SSAT formula is defined as 
	\[
	\exists e_1, \dots, \exists e_n, \R^{p_1} r_1, \dots, \R^{p_m} r_m, \; \phi (E,R). 
	\]
	
	
	is to evaluate a Boolean formula containing both existential and randomized quantifiers~\cite{littman2001stochastic}.  For example:
	
	\[
	\exists x_1, \R^{p_2} y_2, \exists x_3, \dots, \R^{p_n} y_n (E[\phi (\mathbf{x})]\ge \theta)
	\]
	
	In words, this formula asks whether there is a value for $ x_1 $ such that for random values of $ y_2 $ (choose $ y_2 = 1 $ with probability $ p_2 $), there exists a value of $ x_2 $, such that$ \dots $ the expected value of the Boolean formula $ \phi(\mathbf{x}) $ meets or exceeds a threshold $ 0 \le \theta \le 1 $. Here variables $ x_i, y_i \in \mathbf{x} $ are Boolean. 
	
	While the above definition of SSAT has alternating quantifiers, it is not a strict restriction. One could first place random quantifiers followed by exists quantifiers or vice versa. Moreover, the threshold $ \theta $ can be omitted from the definition where the question is to find out the probability of $ \phi(\mathbf{x}) =1 $ given the quantifiers over Boolean variables $ x_i $ and $ y_i $.  
	
\end{comment}





