\section{{\justicia}: An SSAT-based Fairness Verifier}
\label{fairness_justicia_sec:framework}
In this section, we present the primary contribution of this chapter, {\justicia}, which is an SSAT-based framework for verifying group and causal fairness metrics. Given a binary classifier $\alg$, a probability distribution over features $(\nonsensitive,\sensitive,Y) \sim \mathcal{D} $, and a target fairness metric $ f(\alg, \mathcal{D}) $, our goal is to estimate the fairness $ f(\alg, \mathcal{D}) $ of the classifier $ \alg $ given the distribution $ \mathcal{D} $ according to the fairness definition. Additionally, if a fairness threshold $ \epsilon \in [0,1] $ is provided, {\justicia} verifies whether the classifier is $ \epsilon $-fair by comparing $ f $ with $ \epsilon $. In {\justicia}, we focus on classifiers that can be represented as a CNF formula defined over a set of Boolean variables. Additionally, for each variable, we query the distribution $ \mathcal{D} $ to derive the marginal probability of the variable to be assigned to $ 1 $. In this section, we discuss two equivalent approaches for fairness verification based on SSAT-based encodings: \emph{enumeration} approach and \emph{inference} approach. In both approaches, we verify fairness with the presence of compound sensitive groups.  We then provide a theoretical analysis for a high-probability error bound on the fairness metric and conclude with an extension of {\justicia} in practical settings.




\iffalse
In this section, we present the main contribution of this paper, {\justicia}, which is an SSAT framework for verifying independence and separation metrics of fairness. 
We first state the problem formally in Section~\ref{fairness_justicia_sec:problem_statement}. 
To verify fairness metrics in compound sensitive groups, we discuss an enumeration approach in Section~\ref{fairness_justicia_sec:enumeration_ssat} and an equivalent but more efficient learning approach in Section~\ref{fairness_justicia_sec:learn_ssat}. 
We conclude this section by proposing a conditional distribution based enumeration for compound sensitive groups in Section~\ref{fairness_justicia_sec:cond_ssat}. 


\subsection{Problem Statement}
\label{fairness_justicia_sec:problem_statement}
Given a binary classifier $\alg$ and a probability distribution over dataset $(X,A,Y) \sim \mathcal{D} $, our goal is to verify whether $\alg$ achieves independence and separation metrics with respect to the distribution $\mathcal{D}$. We  focus on a classifier that can be translated to a CNF formula of Boolean variables $\mathbf{B} $. 
The probability $ p_i $ of $\bool_i \in \mathbf{B}$ being assigned to $1$ is induced by the data generating distribution $\mathcal{D}$. 
In our contribution, we reduce the verification problem to solving appropriately designed SSAT instances.
\fi 

\subsection{Enumeration Approach  using RE-SSAT encoding}
\label{fairness_justicia_sec:enumeration_ssat}
In order to estimate $ f(\alg, \mathcal{D}) $ in the enumeration approach, the key idea  is to compute the conditional probability of positive prediction of the classifier, $\Pr[\widehat{Y} = 1 | \sensitive = \mathbf{a}]$, for the compound sensitive group $\sensitive = \mathbf{a}$ by solving an appropriately designed SSAT formula.  For simplicity, we  initially make assumptions on the classifier $ \alg $ and discuss practical relaxations later in this section.  We first assume $\alg$ to be represented as a CNF formula, denoted by $\phi_{\widehat{Y}}$, such that the prediction $ \widehat{Y} = 1 $ when $ \phi_{\widehat{Y}}$ is satisfied and  $\widehat{Y} =0$ otherwise. Additionally, all features $ \nonsensitive \cup \sensitive $ are assumed to be Boolean variables.  Finally, we consider independence probability assumption of non-sensitive features $ \nonsensitive $, where $p_i \triangleq \Pr[X_i = 1] $ is the marginal probability of $ X_i $. 



Now, we define an RE-SSAT formula $\Phi_{\mathbf{a}}$ to compute the conditional probability $\Pr[\widehat{Y} = 1 | \sensitive = \mathbf{a}]$ using the probability of satisfaction of $\Phi_{\mathbf{a}}$. In the prefix of $ \Phi_{\mathbf{a}} $,  all non-sensitive features $ \nonsensitive $ are assigned randomized quantifiers and they are followed by sensitive features $ \sensitive $ with existential quantifiers.  In addition, the CNF formula $ \phi $ in the SSAT formula $ \Phi_{\mathbf{a}} $ is constructed such that $ \phi $ encodes the event inside the target probability $ \Pr[\widehat{Y} = 1 | \sensitive = \mathbf{a}] $. In order to specify the sensitive group $ \sensitive = \mathbf{a} $, we take the conjunction of the Boolean variables in $ \sensitive $ that symbolically specifies the compound sensitive group $ \sensitive = \mathbf{a} $. For example, let us consider two sensitive features: race $ \in $ \{White, Colour\} and sex $ \in $ \{male, female\} by Boolean variables $ R $ and $ S $,  respectively. Hence, the compound groups $ [\textrm{White}, \textrm{male}] $ and $[\textrm{Colour}, \textrm{female}]$ are represented by $ R \wedge S $ and $ \neg R \wedge \neg S $, respectively. Thus, the RE-SSAT formula for computing the probability  $ \Pr[\widehat{Y} = 1 | \sensitive = \mathbf{a}] $ is
\begin{equation}	\label{fairness_justicia_eq:re}
\begin{split}
	\Phi_{\mathbf{a}} := \underbrace{\R^{p_{1}}X_1, \dots, \R^{p_{\numnonsensitive}}X_{\numnonsensitive}}_{\text{non-sensitive features}},  &\underbrace{\exists A_1,\dots, \exists A_{\numsensitive}}_{\text{sensitive features}},
\phi_{\widehat{Y}} \wedge (\sensitive =\mathbf{a}).\notag
\end{split}
\end{equation}
In the RE-SSAT formula $ \Phi_{\mathbf{a}} $, existentially quantified variables  $ \{A_1, \dots, A_{\numsensitive}\} $ are assigned Boolean values  according  to the constraint $ \sensitive =\mathbf{a} $.\footnote{An RE-SSAT formula becomes an R-SSAT formula when the assignment to the existential variables are fixed.} Next,  an SSAT solver computes the probability $ \Pr[\Phi_{\mathbf{a}}] $ by considering the random values of $ \{X_1, \dots, X_{\numnonsensitive}\} $ while fixing the assignment of $ \{A_1, \dots, A_{\numsensitive}\} $. Therefore, $ \Pr[\Phi_{\mathbf{a}}] $ equals the conditional probability of positive prediction of the classifier, $ \Pr[\widehat{Y} = 1 | \sensitive = \mathbf{a}] $, for the sensitive group $ \sensitive = \mathbf{a} $. 

For simplicity, we have described the computation of conditional probability $ \Pr[\widehat{Y} = 1 | \sensitive = \mathbf{a}] $ without considering the correlation among sensitive and non-sensitive features. In reality, correlation exists among these features (for a detailed study on feature correlations in fairness verification, we refer to Chapter~\ref{chapter:fvgm}). As a result, non-sensitive features may have different conditional distributions for different sensitive groups. For a non-sensitive feature $ X_i $, we incorporate its conditional probability in the RE-SSAT encoding by setting $ p_i = \Pr[X_i = 1| \sensitive =\mathbf{a}] $ instead of the independent probability $\Pr[X_i = 1]$. Next, we illustrate this enumeration approach in Example~\ref{fairness_justicia_example:re_ssat}.
%This relaxes the independence requirement.

\begin{example}[RE-SSAT encoding]
	\normalfont
	\label{fairness_justicia_example:re_ssat}
	We illustrate the RE-SSAT encoding for calculating the probability of positive prediction for the sensitive group age $ \ge 40 $ in the decision tree of Figure~\ref{fairness_justicia_fig:fair_example}. We assign three Boolean variables $ F,I,J $ for three nodes in the decision tree, where literal $ F,I,J $ denote fitness $ \ge 0.61 $, income $ \ge 0.29 $, and income $ \ge 0.69 $, respectively. We consider another Boolean variable $A$  where the literal $ A $ represents the sensitive group age $ \ge 40 $ and $ \neg A $ denotes age $ < 40 $. Thus, the CNF formula  for the decision tree is $ (\neg F \vee I) \wedge (F \vee J) $. From the distribution in Figure~\ref{fairness_justicia_fig:fair_example}, we get $ \Pr[F] = 0.41, \Pr[I] = 0.93 $, and $ \Pr[J] = 0.09 $. Given this information, we calculate the probability of positive prediction for the sensitive group age $ \ge 40 $ by solving the following RE-SSAT formula:
	
	\begin{equation}
	\Phi_A := \R^{0.41}F, \R^{0.93}I, \R^{0.09}J, \exists A, \; (\neg F \vee I) \wedge (F \vee J) \wedge A.\notag
	\end{equation}
	
	From the solution to this SSAT formula, we get $ \Pr[\Phi_A] = 0.43 $. Similarly, to calculate the probability of positive prediction for the group age $ < 40 $, we replace the unit clause\footnote{A unit clause is a clause with a single literal.} $ A $ with $ \neg A $ in the CNF formula in $ \Phi_A $ and construct another SSAT formula $ \Phi_{\neg A} $. 
	
	\[ \Phi_{\neg A} := \R^{0.41}F, \R^{0.93}I, \R^{0.09}J, \exists A, \; (\neg F \vee I) \wedge (F \vee J) \wedge \neg A \]
	
	For $ \Phi_{\neg A} $, the solution $ \Pr[\Phi_{\neg A}] = 0.43 $ is similarly derived from an SSAT solver. 
	Therefore, if $\Pr[F], \Pr[I], \Pr[J]$ are computed independently of the sensitive feature $A$, both age groups demonstrate equal probability of positive prediction as the sensitive feature is not explicitly present in the classifier. 

	However, there is an implicit bias in the data distribution for different sensitive groups and the classifier unintentionally learns it. To capture this implicit bias, we calculate conditional probabilities  $ \Pr[F|A] = 0.01, \Pr[I|A] = 0.99 $, and $ \Pr[J|A] = 0.18 $ from the distribution for group age $ \ge 40 $ in Figure~\ref{fairness_justicia_fig:fair_example}. Providing the conditional probabilities, we construct a modified SSAT formula $\Phi'_A $ and compute $ \Pr[\Phi'_A] = 0.18 $ for age $ \ge 40 $. 
	
	\begin{equation}
	\Phi'_A := \R^{0.01}F, \R^{0.99}I, \R^{0.18}J, \exists A, \; (\neg F \vee I) \wedge (F \vee J) \wedge A\notag
	\end{equation}
	
	For the sensitive group age $ < 40 $,  we similarly obtain $ \Pr[F|\neg A] = 0.82, \Pr[I|\neg A] = 0.88 $, $ \Pr[J|\neg A] = 0.01 $, construct the modified formula $ \Phi'_{\neg A} $ and get  $ \Pr[\Phi'_{\neg A}] = 0.72 $. 

	\[ \Phi'_{\neg A} := \R^{0.82}F, \R^{0.88}I, \R^{0.01}J, \exists A, \; (\neg F \vee I) \wedge (F \vee J) \wedge \neg A \]	

	In the later case with correlations among sensitive and non-sensitive features, the RE-SSAT encoding detects the discrimination of the classifier among different sensitive groups, where the classifier is more biased towards the younger group with age $ < 40 $ than the elderly group with age $ \ge 40 $.
	
	

	
	
%	An astute reader would observe that $I$ and $J$ are not independent. Following~\cite{chavira2008probabilistic}, we can simply capture relationship between the variables using constraints and if needed, auxiliary variables. In this case, it suffices to add the the constraint $J \rightarrow I$. 
\end{example}

\subsubsection{Measuring Fairness Metrics}
As we compute $ \Pr[\Phi_\mathbf{a}] = \Pr[\widehat{Y} = 1 | \sensitive = \mathbf{a}] $ by solving the SSAT formula $ \Phi_\mathbf{a} $, we  use $ \Pr[\Phi_\mathbf{a}] $ to measure different fairness metrics. To this end, we compute $ \Pr[\Phi_\mathbf{a}] $ for all compound groups $\mathbf{a} \in \sensitive $ by solving an exponential number (with $ \numsensitive $) of SSAT formulas. We elaborate this enumeration approach, namely {\justiciaenum}, in Algorithm~\ref{fairness_justicia_algo:enum}  (Line~\ref{fairness_justicia_algo:justicia_enum_begin}--\ref{fairness_justicia_algo:justicia_enum_end}).

\begin{algorithm}[t!]
	\caption{\justicia: An SSAT-based Fairness Verifier}
	\label{fairness_justicia_algo:enum}
	\begin{algorithmic}[1]
		\Function{{\justiciaenum}}{$ \nonsensitive, \sensitive,\widehat{Y} $}
		\label{fairness_justicia_algo:justicia_enum_begin}
		\State $ \phi_{\widehat{Y}} := \mathsf{CNF}(\widehat{Y} = 1) $
		%\State $ p_{i} = \mathsf{CalculateProb}(X_i), \forall X_i \in X $
		\ForAll{$\mathbf{a} \in \sensitive$ }
		\State $ p_{i} \leftarrow \Pr[X_i = 1|\sensitive = \mathbf{a}], \forall X_i \in \nonsensitive $
		\State $ \phi := \phi_{\widehat{Y}} \wedge (\sensitive =\mathbf{a}) $
		\State $  \Phi_\mathbf{a} := \R^{p_{1}}X_1, \dots, \R^{p_{\numnonsensitive}}X_{\numnonsensitive}, \exists A_1,\dots, \exists A_{\numsensitive},  \phi $
		\State $ \Pr[\Phi_\mathbf{a}]  \leftarrow \mathsf{SSAT}(\Phi_\mathbf{a}) $ \Comment{returns a probability}
		\EndFor
		\State\Return $ \max_{\mathbf{a} \in \sensitive} \Pr[\Phi_{\mathbf{a}}], \min_{\mathbf{a} \in \sensitive} \Pr[\Phi_{\mathbf{a}}] $
		\label{fairness_justicia_algo:justicia_enum_end}
		\EndFunction
		\Statex
		
		
		
		\Function{{\justicialearn}}{$ \nonsensitive, \sensitive,\widehat{Y} $}
		\label{fairness_justicia_algo:justicia_learn_begin}
		\State $ \phi_{\widehat{Y}} := \mathsf{CNF}(\widehat{Y}  = 1) $
		\State $ p_{i} \leftarrow \Pr[X_i=1], \forall X_i \in \nonsensitive $
		\State $  \Phi_\mathsf{ER} := \exists A_1,\dots, \exists A_{\numsensitive}, \R^{p_{1}}X_1, \dots, \R^{p_{\numnonsensitive}}X_{\numnonsensitive}, \phi_{\widehat{Y}} $
		\State $  \Phi'_\mathsf{ER} := \exists A_1,\dots, \exists A_{\numsensitive}, \R^{p_{1}}X_1, \dots, \R^{p_{\numnonsensitive}}X_{\numnonsensitive}, \neg \phi_{\widehat{Y}} $
		\State\Return $ \mathsf{SSAT}(\Phi_\mathsf{ER}), 1 - \mathsf{SSAT}(\Phi'_\mathsf{ER}) $
		\label{fairness_justicia_algo:justicia_learn_end}
		\EndFunction
	\end{algorithmic}

\end{algorithm}


To measure the disparate impact of a classifier, we calculate the ratio between the minimum and the maximum conditional probability of positive prediction of the classifier, which are  $ \min_{\mathbf{a} \in \sensitive} \Pr[\Phi_{\mathbf{a}}] $ and $ \max_{\mathbf{a} \in \sensitive} \Pr[\Phi_{\mathbf{a}}] $, respectively. We compute statistical parity by taking the difference between $ \max_{\mathbf{a} \in \sensitive} \Pr[\Phi_{\mathbf{a}}] $ and $ \min_{\mathbf{a} \in \sensitive} \Pr[\Phi_{\mathbf{a}}] $. 


Moreover, to compute equalized odds, we call {\justicia} twice, one for the distribution $ \mathcal{D} $ conditioned on $ Y = 1  $ and another for $ Y = 0 $. In both calls, we compute $ \max_{ \mathbf{a}} \Pr[\widehat{Y} =1 | \sensitive = \mathbf{a}, Y = y ]  - \min_{ \mathbf{a}} \Pr[\widehat{Y} =1 | \sensitive = \mathbf{a}, Y = y ] $ for $ y \in \{0,1\} $ and take the  maximum difference as the value of equalized odds. 
For measuring path-specific causal fairness, we compute  $ \max_{ \mathbf{a}} \Pr[\widehat{Y} =1 | \sensitive = \mathbf{a}, \mathbf{Z}] $ and  $ \min_{ \mathbf{a}} \Pr[\widehat{Y} =1, \mathbf{Z}| \sensitive = \mathbf{a} , \mathbf{Z}] $ by conditioning the distribution $ \mathcal{D} $ by mediator features $ \mathbf{Z} $ and take their difference. Thus, {\justiciaenum} allows us to compute different group and causal fairness metrics using a unified algorithmic framework.





\subsection{Inference Approach using ER-SSAT Encoding}
\label{fairness_justicia_sec:learn_ssat}
In most practical problems, there can be exponentially many compound sensitive groups due to the combination of categorical sensitive features.  As a result, the enumeration approach may suffer from scalability issues due to an exponential number of calls to the SSAT solver. To this end, we propose an efficient SSAT encoding, where we make two SSAT calls, one for inferring the \emph{the most favored sensitive group} with the maximum conditional probability of positive prediction of the classifier and another for inferring \emph{the least favored sensitive group} with the minimum conditional probability of positive prediction of the same classifier. As discussed above, these two probabilities are sufficient to measure different group and causal fairness metrics.

\todo{End of revision}

\subsubsection{Inferring the Most Favored Sensitive Group}
In the prefix of an SSAT formula $ \Phi $, the order of quantified variables carries distinct interpretation of  $ \Pr[\Phi] $.   In an ER-SSAT formula, $ \Pr[\Phi] $ is the \textit{maximum} satisfying probability of $ \Phi $ over the optimal assignment of existentially quantified variables given the randomized quantified variables (by Semantic 2, Sec.~\ref{fairness_justicia_sec:ssat}). In this chapter, we leverage this property to compute the most favored sensitive group with the highest probability of positive prediction of the classifier. In particular, we consider the following ER-SSAT formula:

\begin{equation}
\Phi_{\mathsf{ER}} := \exists A_1,\dots, \exists A_{\numsensitive},
 \R^{p_{1}}X_1, \dots, \R^{p_{\numnonsensitive}}X_{\numnonsensitive},   \; \phi_{\widehat{Y}}.
 \label{fairness_justicia_eq:er}
\end{equation}

The CNF formula $\phi_{\widehat{Y}}$ in $ \Phi_{\mathsf{ER}} $ is the CNF translation  of the classifier $ \widehat{Y} = 1 $ without any specification of the compound sensitive group.  Therefore, as we solve $ \Phi_{\mathsf{ER}} $, we find the optimal assignment to the existentially quantified variables $ A_1 = a^{\max}_1, \dots,A_{\numsensitive} = a^{\max}_{\numsensitive} $ for which the probability of satisfaction of the ER-SSAT formula $ \Pr[\Phi_{\mathsf{ER}}] $ becomes maximum. Thus, we compute  the most favored group $ \mathbf{a}_{\max} \triangleq [ a^{\max}_1, \dots, a^{\max}_{\numsensitive} ] $ achieving the highest probability of positive prediction of the classifier. 


\subsubsection{Inferring the Least Favored Sensitive Group}
In order to infer the least favored sensitive group of the classifier, we  compute the \textit{minimum} conditional probability of positive prediction of the classifier with respect to all sensitive groups given the random values of the non-sensitive features. To this end, we  solve a `universal-random' (UR) SSAT formula with  universal quantifiers over sensitive features and randomized quantification over non-sensitive features (by Semantic 3, Sec.~\ref{fairness_justicia_sec:ssat}).
\begin{equation}
\Phi_{\mathsf{UR}} := \forall A_1,\dots, \forall A_{\numsensitive},
\R^{p_{1}}X_1, \dots, \R^{p_{\numnonsensitive}}X_{\numnonsensitive},   \; \phi_{\widehat{Y}}
\label{fairness_justicia_eq:ar}
\end{equation}
%By solving $ \Phi_{\mathsf{UR}} $, we find the optimal assignment to the universally quantified variables $ A_1 = a^{\min}_1, \dots,A_{\numsensitive} = a^{\min}_{\numsensitive} $ for which the probability of satisfaction of the UR-SSAT formula $ \Pr[\Phi_{\mathsf{UR}}] $ becomes minimum. Thus, $ \red{\mathbf{a}_{\min}} \triangleq [ a^{\min}_1, \dots, a^{\min}_{\numsensitive} ] $ becomes the least favored sensitive group achieving the lowest probability of positive prediction of the classifier. 

Solving an UR-SSAT formula raises several practical issues and thus, there is an unavailability of a UR-SSAT solver. To resolve this problem, we leverage the \textit{duality} between UR-SSAT  and ER-SSAT formulas, where we solve an UR-SSAT formula on the CNF $ \phi $ using the solution of an ER-SSAT formula on the complemented CNF $ \neg \phi $~\cite{littman2001stochastic}. More specifically, we solve the following ER-SSAT formula for finding the least favored sensitive group.

\begin{equation}
	\Phi'_{\mathsf{ER}} := \exists A_1,\dots, \exists A_{\numsensitive},
	\R^{p_{1}}X_1, \dots, \R^{p_{\numnonsensitive}}X_{\numnonsensitive},   \; \neg \phi_{\widehat{Y}}
	\label{fairness_justicia_eq:er_complement}
\end{equation}


In Lemma~\ref{fairness_justicia_thm:dual}, we discuss the duality between UR-SSAT and ER-SSAT formulas.


\begin{lemma}\label{fairness_justicia_thm:dual}
Given Eq.~\eqref{fairness_justicia_eq:ar} and~\eqref{fairness_justicia_eq:er_complement},	$ \Pr[\Phi_{\mathsf{UR}}] = 1 - \Pr[\Phi'_{\mathsf{ER}}]  $.
\end{lemma}

\begin{proof}[Proof of Lemma~\ref{fairness_justicia_thm:dual}]
	Both $ \Phi_{\mathsf{UR}} $ and $ \Phi'_{\mathsf{ER}} $ have  random quantified variables in the identical order in the prefix. According to the definition of SSAT formulas,
	\begin{equation*}
	\Pr[\Phi_{\mathsf{UR}}] = \min\limits_{a_1, \dots,a_{\numsensitive}} \Pr[\phi_{\widehat{Y}}] \text{ and } \Pr[\Phi'_{\mathsf{ER}}] = \max\limits_{a_1, \dots,a_{\numsensitive}} \Pr[\neg\phi_{\widehat{Y}}],
	\end{equation*}
	
	where $ \Pr[\phi_{\widehat{Y}}] $ and $ \Pr[\neg \phi_{\widehat{Y}}] $ are both computed for the random values of non-sensitive features $ \nonsensitive $.
	
	Therefore, we derive the following duality between ER-SSAT and UR-SSAT,
	\begin{equation}
	\begin{split}
	\Pr[\Phi'_{\mathsf{ER}}] &= \max\limits_{a_1, \dots,a_{\numsensitive}} \Pr[\neg\phi_{\widehat{Y}}]  \\
	&= \min\limits_{a_1, \dots,a_{\numsensitive}} (1 - \Pr[\phi_{\widehat{Y}}])\\
	&= 1 - \min\limits_{a_1, \dots,a_{\numsensitive}}  \Pr[\phi_{\widehat{Y}}]\\
	&= 1 - \Pr[\Phi_{\mathsf{UR}}].\notag
	\end{split}
	\end{equation}
\end{proof}


As we solve $\Phi'_{\mathsf{ER}}$, we obtain the optimal assignment to the sensitive features $\mathbf{a}_{\min} \triangleq [a^{min}_1, \dots, a^{min}_{\numsensitive}]$ that maximizes $\Phi'_{\mathsf{ER}}$.  If $ p $ is the maximum satisfying probability of $ \Phi'_{\mathsf{ER}} $, then according to Lemma~\ref{fairness_justicia_thm:dual}, $ 1 - p $ is the minimum satisfying probability of $ \Phi_{\mathsf{UR}} $;  which is also the minimum probability of positive prediction of the classifier. We present the algorithm for the inference approach, namely {\justicialearn} in Algorithm~\ref{fairness_justicia_algo:enum} (Line~\ref{fairness_justicia_algo:justicia_learn_begin}--\ref{fairness_justicia_algo:justicia_learn_end}).

\iffalse
\begin{algorithm}[t!]
	\caption{\justicialearn: Learning ER-SSAT Encoding}
	\label{fairness_justicia_algo:learn}
	\begin{algorithmic}[1]
		\Function{{\justicialearn}}{$ X,A,\widehat{Y} $}
		\State $ \phi_{\widehat{Y}} = \mathsf{CNF}(\widehat{Y}  = 1) $
		\State $ p_{i} = \mathsf{CalculateProb}(x_i), \forall x_i \in X $
		\State $  \Phi_\mathbf{ER} = \exists a_1,\dots, \exists a_{\numsensitive}, \R^{p_{1}}x_1, \dots, \R^{p_{\numnonsensitive}}x_{\numnonsensitive}. \; \phi_{\widehat{Y}} $
		\State $  \Phi'_\mathbf{ER} = \exists a_1,\dots, \exists a_{\numsensitive}, \R^{p_{1}}x_1, \dots, \R^{p_{\numnonsensitive}}x_{\numnonsensitive}. \; \neg \phi_{\widehat{Y}} $
		\State \Return $ \mathsf{SSAT}(\Phi_\mathbf{ER}), 1 - \mathsf{SSAT}(\Phi'_\mathbf{ER}) $
		\EndFunction
	\end{algorithmic}
\end{algorithm}
\fi

In the ER-SSAT formula in Eq.~\eqref{fairness_justicia_eq:er_complement}, we need to negate the classifier $ \phi_{\widehat{Y}} $ to another CNF formula $ \neg \phi_{\widehat{Y}} $. The na\"ive approach of negating one CNF to another CNF generates an exponential number of new clauses. Here, we apply Tseitin transformation for the negation, which increases the number of clauses linearly while introducing a linear number of new variables~\cite{tseitin1983complexity}. As an alternative approach, we directly encode the binary classifier $\alg$ for the negative class label $\widehat{Y} = 0$ as a CNF formula and pass it to $\Phi'_{\mathsf{ER}} $, whenever it is possible. The latter approach is generally more efficient than the former approach as the resulting CNF is often smaller.  






\begin{example}[ER-SSAT encoding]
	\normalfont
	\label{fairness_justicia_example:er_ssat}
	Here, we illustrate the ER-SSAT encoding for inferring the most favored and the least favored sensitive group of a classifier in the presence of compound sensitive groups. As the example in Figure~\ref{fairness_justicia_fig:fair_example} is degenerate for this purpose, we introduce another Boolean sensitive feature `sex' $ \in $ \{male, female\}. We consider a Boolean variable $ S $ for sex where the literal $ S $ denotes sex = male. With this new sensitive feature, let the classifier be  $\alg \triangleq (\neg F \vee I \vee S) \wedge (F \vee J)$, where variables corresponding to sensitive features $ F,I$, and  $J $ have same distributions as discussed in Example~\ref{fairness_justicia_example:re_ssat}. Hence, we obtain the following ER-SSAT formula of $\alg$ to infer the most favored sensitive group:
	
	\[ \Phi_{\mathsf{ER}} =  \exists S,\exists A, \R^{0.41}F, \R^{0.93}I, \R^{0.09}J, \; (\neg F \vee I \vee S) \wedge (F \vee J).
	\]
	
	As we solve $ \Phi_{\mathsf{ER}} $, we infer that the optimal assignment to the existential variables $ \sigma(S) = 1, \sigma(A) = 0$, which implies that `male individuals with age $ < 40 $' is the most favored group with probability of positive prediction computed as $ \Pr[\Phi_{\mathsf{ER}}] = 0.46$. Similarly, to infer the least favored group, we negate the CNF translation of the classifier $\alg$ to obtain the following ER-SSAT formula:
	
	\[\Phi'_{\mathsf{ER}} =  \exists S, \exists A, \R^{0.41}F, \R^{0.93}I, \R^{0.09}J, \; \neg((\neg F \vee I \vee S) \wedge (F \vee J)).
	\]
	
	Solving $ \Phi'_{\mathsf{ER}} $, we learn the optimal assignment $ \sigma(S) = 0, \sigma(A) = 0  $ and $  \Pr[\Phi'_{\mathsf{ER}}] = 0.57 $. Thus, `female individuals with age $ < 40 $' constitute the least favored group with probability of positive prediction as  $ 1-0.57 = 0.43$. 
	Thus, {\justicialearn} allows us to infer the most and least favored sensitive groups and the corresponding discrimination.
\end{example}



We next prove the equivalence of {\justiciaenum} and {\justicialearn} in Lemma~\ref{fairness_justicia_lm:equivalence}.

\begin{lemma}
	\label{fairness_justicia_lm:equivalence}
	Let $ \Phi_{\mathbf{a}} $ be an RE-SSAT formula for computing the probability of positive prediction of a classifier corresponding to the sensitive group $  \sensitive = \mathbf{a} $. Additionally, for the same classifer, let $ \Phi_{\mathsf{ER}} $ be an ER-SSAT formula for inferring the most favored sensitive group and $ \Phi_{\mathsf{UR}} $ be a UR-SSAT formula for inferring the least favored sensitive group.  Therefore,	$\max_{\mathbf{a} \in \sensitive} \; \Pr[\Phi_{\mathbf{a}}] = \Pr[\Phi_{\mathsf{ER}}]$   	and	$\min_{\mathbf{a} \in \sensitive} \; \Pr[\Phi_{\mathbf{a}}] = \Pr[\Phi_{\mathsf{UR}}]$.  
\end{lemma}

\begin{proof}[Proof of Lemma~\ref{fairness_justicia_lm:equivalence}] 
	It is trivial that the probability of positive prediction of the classifier for the most favored group $ \mathbf{a}_{\max} $ is the maximum computed probability of all compound groups $ \mathbf{a} \in \sensitive $. Similar argument holds for the least favored group $ \mathbf{a}_{\min} $, which obtains the minimum probability of positive prediction of the classifier among all compound groups $ \mathbf{a} \in A $.
	
	By construction of the SSAT formulas, $ \Pr[\Phi_{\mathsf{ER}}] $ and $ \Pr[\Phi_{\mathsf{UR}}] $ are the probabilities corresponding to the groups $ \sensitive = \mathbf{a}_{\max} $ and $ \sensitive = \mathbf{a}_{\min} $, respectively. Now, since $ \Pr[\Phi_{\mathbf{a}}] $ is the probability for the group $ \sensitive = \mathbf{a} $, we derive the following.
	
	\begin{equation*}
	\begin{split}
	\max_{\mathbf{a} \in \sensitive} \; \Pr[\Phi_{\mathbf{a}}] = \Pr[\Phi_{\mathsf{ER}}]
	\text{ and }
	\min_{\mathbf{a} \in \sensitive} \; \Pr[\Phi_{\mathbf{a}}] = \Pr[\Phi_{\mathsf{UR}}]
	\end{split}
	\end{equation*}
\end{proof}


\iffalse
\begin{theorem}
	For an ER-SSAT problem, the na\"ive sample complexity is given by 
	\[ k = O\left(\frac{1}{\epsilon^2} (n + \ln(1/\delta))  \right)\]
	where $\widehat{p} - p \leq \epsilon$ with probability $1-\delta$.
\end{theorem}
\red{For a simple sampling based algo after evaluating $k$ assignments, the error between estimates probability and actual probability would differ by $\epsilon$ with probability $1- 2^{n+1} e^{-2\epsilon^2 k}$. So the sample complexity of a naive algo is $k = O(\epsilon^{-2} (\log(1/\delta) + n))$.}
\fi

%\subsection{Conditionally Evaluating an SSAT Encoding}
%\label{fairness_justicia_sec:cond_ssat}


%\begin{algorithm}[t!]
%	\caption{\justiciacond: Conditional Evaluation of RE Encoding \red{Can be removed, only difference is in line 4}}
%	\begin{algorithmic}[1]
%		\Function{{\justiciacond}}{$ X,A,\widehat{Y} $}
%		\State $ \phi_{\widehat{Y}} = \mathsf{CNF}(\widehat{Y}  = 1) $
%		\ForAll{$\mathbf{a} \in A$ }
%		\State $ p_{i} = \mathsf{\blue{calculateCondProb}}(x_i, \mathbf{a}), \forall x_i \in X $
%		\State $  \Phi_\mathbf{a} = \R^{p_{1}}x_1, \dots, \R^{p_{\numnonsensitive}}x_{\numnonsensitive}, \exists A_1,\dots, \exists A_{\numsensitive}. \; \phi_{\widehat{Y}} \wedge \mathsf{CNF}(\sensitive =\mathbf{a}) $
%		\State $ \Pr[\Phi_\mathbf{a}]  = \ma
%thsf{SSAT}(\Phi_\mathbf{a}) $
%		\EndFor
%		\State \Return $ \max\limits_{\mathbf{a}} \; \Pr[\Phi_{\mathbf{a}}], \min\limits_{\mathbf{a}} \; \Pr[\Phi_{\mathbf{a}}] $
%		\EndFunction		
%	\end{algorithmic}
%\end{algorithm}

\iffalse
\red{While it is trivial to use conditional probability distribution for the RE encoding, it is not straightforward for the presented ER-encoding, which we leave as a future work. 
}
\fi

\begin{comment}
\red{Let $ \bool_i $ and $ \bool_j $ be two Boolean (non-sensitive) features and we want to encode their pair-wise correlation in {\justicia}. For an assignment to $ \bool_i, \bool_j $, we consider a new Boolean variable $ v $ and add a constraint $ v \leftrightarrow \bool_i \wedge \bool_j $ in the CNF $ \phi $ of the SSAT formula $ \Phi $. Additionally, $ v $ is given a randomized quantification in the prefix of $ \Phi $ and the probability of $ v $ is calculated as the probability of both $ \bool_i $ and $ \bool_j $ assigning to $ 1 $ in the distribution $ \mathcal{D} $. Note that, to encode the total correlation of all Boolean features, the mentioned approach introduces exponentially (with the number of features) many new variables and add an exponential number of constraints to $ \phi $ with an aim of computing a more precise satisfying probability of $ \Phi $. Optionally, one can encode the correlation among a selected set of features of interest in {\justicia}. }
\end{comment}


\subsection{Theoretical Analysis: Error Bounds}\label{fairness_justicia_sec:theory}
For practical fairness problems, we do not have access to the distribution of features rather to a finite-sample dataset. Since the input of {\justicia} is the distribution of features, we compute the distribution from the dataset. The finite-sample dataset introduces errors in the computed probabilities of randomized quantified features being assigned to $1$. These finite-sample errors in computed probabilities induce further errors in the computed probability of positive prediction of the classifier and corresponding fairness metrics. We next provide a bound on this finite-sample error.

Let us consider that $\widehat{p_i}$ is the estimated probability of a Boolean variable $ \bool_i $ being assigned to $ 1 $ from $ n $ samples, and $p_i$ is the true probability of $ \bool_i = 1 $ according to $ \mathcal{D} $. 
%If $ | p_i - \widehat{p_i}| \le \epsilon $, i.e., $ \epsilon $ additive error for small $ \epsilon \approx 0 $, we want to compute the error of probability $ p $ of the satisfaction of the SSAT formula $ \Phi $.  
Thus, the true satisfying probability $p$ of an SSAT formula $ \Phi $ is the weighted sum of all satisfying assignments of the CNF $ \phi $, $p = \sum_{\sigma^*} \prod_{L_i \in {\sigma^*}}L_i * p_i + (1 - L_i) * (1 - p_i)$, where the literal $ L_i \in \{0,1\} $ denotes either the variable $ B_i $ when $ L_i = 1 $ or its negation when $ L_i = 0 $. This probability $ p $ is estimated as $\widehat{p}$ using $n$ samples from the distribution $\mathcal{D}$ such that $\widehat{p} \leq \epsilon_0 p$ for $\epsilon_0 \geq 1$. 
%However, the true satisfying probability $ \widehat{p} $  of $ \Phi $ is 
%\[
%\widehat{p} = \sum_\sigma \prod_{\bool_i \in \sigma}\widehat{p_i}  \leq \sum_\sigma \prod_{\bool_i \in \sigma}(1 \pm \epsilon_i) p_i = \prod_{i =1}^m (1 \pm \epsilon_i) p = \epsilon_0 p
%\]
\iffalse
If we consider $\epsilon_i = \frac{\ln \epsilon_0}{2^i}$, we obtain
\begin{equation*}
\begin{split}
\prod_{i =1}^m (1 \pm \epsilon_i) &\leq \left(\frac{1}{n} \sum_{i} (1 + \epsilon_i)\right)^n \\
&= (\frac{1}{n} \sum_{i} (1+\frac{\ln \epsilon_0}{2^i})^n\\
&\leq (1  +\frac{\ln \epsilon_0}{n})^n\\
&\leq e^{\ln \epsilon_0} = \epsilon_0.\notag
\end{split}
\end{equation*}
\fi
\begin{theorem}\label{fairness_justicia_thm:sample}
	For an ER-SSAT problem, the sample complexity is given by 
	$ n = O\left((\numsensitive+ \ln(1/\delta))\frac{\ln \numnonsensitive}{\ln \epsilon_0} \right),$
	where $\frac{\widehat{p}}{p} \leq \epsilon_0$ with probability $1-\delta$ such that $\epsilon_0 \geq 1$.
\end{theorem}
\todo{Check correctness of the theorem}
%Theorem~\ref{fairness_justicia_thm:sample} states that for the prescribed number of samples the estimated disparate impact $\widehat{DI}$ and statistical parity $\widehat{SP}$ would also satisfy $\widehat{DI} \leq  \epsilon_0 DI, $ and $\widehat{SP} \leq 2\epsilon_0 SP$.
%Apply Hoeffding inequality for each term and then use Union bound for $2^n$ existential variables.
\begin{corollary}
	\label{fairness_justicia_cor:error}
	If $n$ samples are considered from the  distribution in {\justicia} such that 
	\[
	n = O\left((\numsensitive + \ln(1/\delta))\frac{\ln \numnonsensitive}{\ln \epsilon_0}\right),
	\]
	
	the estimated disparate impact    $\widehat{\mathsf{DI}}$ and statistical parity  $\widehat{\mathsf{SP}}$ satisfy, with probability $1-\delta$,
	\[
	\widehat{\mathsf{DI}} \leq  \epsilon_0 \mathsf{DI},\text{ and }  \widehat{\mathsf{SP}} \leq 2\epsilon_0 \mathsf{SP}.
	\]
\end{corollary}
\todo{Proof is wrong}


\begin{proof}[Proof of Corollary~\ref{fairness_justicia_cor:error}] 
By Theorem~\ref{fairness_justicia_thm:sample}, we get that for $n$ samples obtained from the distribution, where

$$ n \geq (\numsensitive + \ln(1/\delta))\frac{\ln \numnonsensitive}{\ln \epsilon_0},$$

the estimated probability of satisfaction of SSAT formulas for the most and least favored sensitive groups, referred as $\widehat{p}_{max}$ and  $\widehat{p}_{min}$, respectively satisfy

\begin{equation}
\widehat{p}_{max} \leq \epsilon_0 \max_{\mathbf{a} \in \sensitive} \; \Pr[\Phi_{\mathbf{a}}]
\text{ and }
\widehat{p}_{min} \leq \epsilon_0 \min_{\mathbf{a} \in \sensitive} \; \Pr[\Phi_{\mathbf{a}}].\notag
\end{equation}

with probability $ 1-\delta $.
Thus, the estimated value of disparate impact will satisfy

$$\widehat{\mathsf{DI}} \triangleq \frac{\widehat{p}_{max}}{\widehat{p}_{min}} \leq \epsilon_0  \frac{p_{max}}{p_{min}} \leq \epsilon_0 \mathsf{DI},$$

and statistical parity will satisfy 

$$\widehat{SP} \triangleq \abs{\widehat{p}_{max} - \widehat{p}_{min}} \leq  \epsilon_0  \abs{p_{max} - p_{min}} \leq \epsilon_0 SP,$$

with probability $1-\delta$.
\end{proof}


\red{This implies that given a binary classifier represented as a CNF formula and a distribution of sensitive and non-sensitive features, {\justicia} can verify independence and separation notion of fairness up to an error level $\epsilon_0$ and $2\epsilon_0$ with probability $1-\delta$. Thus, {\justicia} is a sound framework of fairness verification with high probability.}
%\red{Proof of all theorems for arxiv version}
%Use definition of $GF = p_1/p_2$.




\iffalse

\begin{corollary}[Hypothesis]
	If $k$ samples are considered in \justicia and the estimated group fairness value $\widehat{GF}$ satisfies
	\begin{equation*}
	1- e^{\epsilon_0} \leq \frac{\widehat{GF}}{GF} \leq 1 + e^{\epsilon_0}
	\end{equation*}
	with probability $1-\delta$, then
	\begin{equation*}
	k = O\left((n+ \ln(1/\delta))\frac{m + \ln m}{\ln \epsilon_0}\right).
	\end{equation*}
\end{corollary}
\fi


