\section{abstract}
	 Machine learning algorithms that produce  rule-based predictions   in Conjunctive Normal form (CNF) or in Disjunctive Normal form (DNF) are arguably some of the most interpretable ones. For example, decision set is an interpretable model in practice, that represents the decision function in the form of DNF. In this paper, we consider relaxed definitions of standard OR/AND operators which allow exceptions in the construction of a clause and also in the selection of clauses in a rule. Building on these relaxed definition,  we introduce \textit{relaxed-}CNF rules, which are motivated by the popular usage of checklists in the medical domain and generalizes the widely employed rule representations including CNF, DNF, and decision sets.  While the combinatorial structure of relaxed-CNF rules offers exponential succinctness, the naive learning techniques are computationally expensive. 	 To this end, we  propose a novel incremental mini-batch learning procedure, called {\crr}, that employs  advances in the  Mixed-Integer Linear Programming (MILP) solvers to efficiently learn relaxed-CNF rules.  
	 Our  experimental analysis demonstrates that {\crr} can generate relaxed-CNF rules, which are more accurate and sparser compared to the alternative rule-based models. 

