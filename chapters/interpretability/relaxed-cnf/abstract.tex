\section{abstract}
	 Machine learning classifiers that produce  rule-based predictions in Boolean representations such as in Conjunctive Normal form (CNF) or in Disjunctive Normal form (DNF) are arguably some of the most interpretable ones. For example, decision set is a popular interpretable model, which represents the decision function in the form of DNF. In this chapter, we consider relaxed definitions of standard OR/AND operators in CNF/DNF, which allow exceptions in the construction of a clause and also in the selection of clauses in a rule. Building on these relaxed definitions,  we introduce \textit{relaxed-}CNF rules, which are motivated by the popular usage of checklists in the medical domain and generalize the widely employed rule representations including CNF, DNF, and decision sets.  While the combinatorial structure of relaxed-CNF rules offers an exponential succinctness, the na\"ive learning techniques are computationally expensive. 	 To this end, we  propose a novel incremental mini-batch learning procedure, called {\crr}, that employs  advances in the  Mixed-Integer Linear Programming (MILP) solvers to efficiently learn relaxed-CNF rules. Our  experimental analysis demonstrates that {\crr} can generate more accurate and sparser relaxed-CNF rules compared to the alternative rule-based classifiers. 


