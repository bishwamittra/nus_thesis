

 \section{Problem Formulation}
 \label{interpretability_imli_sec:problem}
We are given 
\begin{enumerate}
	\item a dataset $ \dataset = \{(\mathbf{x}^{(i)}, y^{(i)})\}_{i=1}^n$ of $ n $ samples, where feature vector $ \mathbf{x}^{(i)} \in \{0, 1\}^m $ contains $ m $ features and class label $ y^{(i)} \in \{0,1\} $,
	\item a positive integer $ k \ge 1 $ denoting the number of clauses to be learned in the classification rule, and
	\item a regularization parameter $ \lambda \in \mathbb{R}^+ $.
\end{enumerate}
Our goal is to learn a rule-based classifier $ \Rule $ represented as a $ k $-clause CNF formula separating samples of class $ 1 $ from class $ 0 $. 
 
 

 We learn classifiers that balance two 
 goals: of  being accurate but also interpretable.  
 Various notions of interpretability have been discussed in the context of   classification problems. A common proxy for interpretability in the context of decision rules 
 is the sparsity of rule. For instance, a rule involving fewer literals is highly interpretable.  In this chapter, we minimize the total number of literals in all clauses, which motivates us to  find $ \Rule  $ with minimum  $ |\Rule| $. Let $ \Rule $ classify all samples correctly during training. Among all the classification rules that classify all samples correctly,  we choose the sparsest (most interpretable) such $ \Rule $. 
 
 

 \[
 \min\limits_{\mathcal{R}} |\mathcal{R}|\text{ such that }\forall i, y^{(i)}=\mathcal{R}(\mathbf{x}^{(i)})
 \]

 

 In practical classification tasks, perfect classification is unlikely. Hence, we need to balance interpretability with classification error.  Let $ \mathcal{E}_\dataset = \{(\mathbf{x}^{(i)},y^{(i)}) | y^{(i)} \ne \mathcal{R}(\mathbf{x}^{(i)}) \} $   be  the set of samples in $ \dataset $ that are misclassified  by $ \mathcal{R} $. Therefore, we balance between classification-accuracy and rule-sparsity and optimize the following function.\footnote{In our formulation, it is  straightforward to add class-conditional weights  (e.g., to penalize  false-alarms more than mis-detects), and to allow instance weights (per sample).}

 \begin{equation}
  \label{interpretability_imli_eq:obj}
 \min\limits_{\mathcal{R}} \;  |\mathcal{E}_\dataset| +\lambda |\mathcal{R}|
 \end{equation}
 
Higher  values of $ \lambda $ generate a rule with a smaller rule size but of more training errors, and vice-versa. Thus, $ \lambda $ can be tuned to trade-off between accuracy and interpretability for a rule-based classifier, which we experiment extensively in Chapter~\ref{interpretability_imli_sec:experiments}.

